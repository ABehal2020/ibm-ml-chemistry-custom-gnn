{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7722a8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityabehal/opt/anaconda3/envs/custom-gnn/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import rdkit, rdkit.Chem, rdkit.Chem.rdDepictor, rdkit.Chem.Draw\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import dense_to_sparse, add_self_loops, to_scipy_sparse_matrix\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from six.moves import urllib\n",
    "import deepchem as dc\n",
    "import random\n",
    "from dgl.nn import Set2Set\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\n",
    "    \"dark\",\n",
    "    {\n",
    "        \"xtick.bottom\": True,\n",
    "        \"ytick.left\": True,\n",
    "        \"xtick.color\": \"#666666\",\n",
    "        \"ytick.color\": \"#666666\",\n",
    "        \"axes.edgecolor\": \"#666666\",\n",
    "        \"axes.linewidth\": 0.8,\n",
    "        \"figure.dpi\": 300,\n",
    "    },\n",
    ")\n",
    "color_cycle = [\"#1BBC9B\", \"#F06060\", \"#5C4B51\", \"#F3B562\", \"#6e5687\"]\n",
    "mpl.rcParams[\"axes.prop_cycle\"] = mpl.cycler(color=color_cycle)\n",
    "\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "soldata = pd.read_csv('https://dataverse.harvard.edu/api/access/datafile/3407241?format=original&gbrecs=true')\n",
    "# had to rehost because dataverse isn't reliable\n",
    "soldata = pd.read_csv(\n",
    "    \"https://github.com/whitead/dmol-book/raw/main/data/curated-solubility-dataset.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64bfb23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_smiles2graph(smiles):\n",
    "    \"\"\"Argument for the RD2NX function should be a valid SMILES sequence\n",
    "    returns: the graph\n",
    "    \"\"\"\n",
    "    featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "    out = featurizer.featurize(smiles)\n",
    "    return out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8af8bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.feat.MolGraphConvFeaturizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce0410af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphData(node_features=[2, 30], edge_index=[2, 2], edge_features=[2, 11])\n",
      "<class 'deepchem.feat.graph_data.GraphData'>\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[0 1]\n",
      " [1 0]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "testCO = gen_smiles2graph(\"CO\")\n",
    "print(testCO)\n",
    "print(type(testCO))\n",
    "print(testCO.node_features)\n",
    "print(type(testCO.node_features))\n",
    "print(testCO.edge_index)\n",
    "print(type(testCO.edge_index))\n",
    "print(testCO.edge_features)\n",
    "print(type(testCO.edge_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ffef1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on GraphData in module deepchem.feat.graph_data object:\n",
      "\n",
      "class GraphData(builtins.object)\n",
      " |  GraphData(node_features: numpy.ndarray, edge_index: numpy.ndarray, edge_features: Union[numpy.ndarray, NoneType] = None, node_pos_features: Union[numpy.ndarray, NoneType] = None, **kwargs)\n",
      " |  \n",
      " |  GraphData class\n",
      " |  \n",
      " |  This data class is almost same as `torch_geometric.data.Data\n",
      " |  <https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data>`_.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  node_features: np.ndarray\n",
      " |    Node feature matrix with shape [num_nodes, num_node_features]\n",
      " |  edge_index: np.ndarray, dtype int\n",
      " |    Graph connectivity in COO format with shape [2, num_edges]\n",
      " |  edge_features: np.ndarray, optional (default None)\n",
      " |    Edge feature matrix with shape [num_edges, num_edge_features]\n",
      " |  node_pos_features: np.ndarray, optional (default None)\n",
      " |    Node position matrix with shape [num_nodes, num_dimensions].\n",
      " |  num_nodes: int\n",
      " |    The number of nodes in the graph\n",
      " |  num_node_features: int\n",
      " |    The number of features per node in the graph\n",
      " |  num_edges: int\n",
      " |    The number of edges in the graph\n",
      " |  num_edges_features: int, optional (default None)\n",
      " |    The number of features per edge in the graph\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> node_features = np.random.rand(5, 10)\n",
      " |  >>> edge_index = np.array([[0, 1, 2, 3, 4], [1, 2, 3, 4, 0]], dtype=np.int64)\n",
      " |  >>> edge_features = np.random.rand(5, 5)\n",
      " |  >>> global_features = np.random.random(5)\n",
      " |  >>> graph = GraphData(node_features, edge_index, edge_features, z=global_features)\n",
      " |  >>> graph\n",
      " |  GraphData(node_features=[5, 10], edge_index=[2, 5], edge_features=[5, 5], z=[5])\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, node_features: numpy.ndarray, edge_index: numpy.ndarray, edge_features: Union[numpy.ndarray, NoneType] = None, node_pos_features: Union[numpy.ndarray, NoneType] = None, **kwargs)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      node_features: np.ndarray\n",
      " |        Node feature matrix with shape [num_nodes, num_node_features]\n",
      " |      edge_index: np.ndarray, dtype int\n",
      " |        Graph connectivity in COO format with shape [2, num_edges]\n",
      " |      edge_features: np.ndarray, optional (default None)\n",
      " |        Edge feature matrix with shape [num_edges, num_edge_features]\n",
      " |      node_pos_features: np.ndarray, optional (default None)\n",
      " |        Node position matrix with shape [num_nodes, num_dimensions].\n",
      " |      kwargs: optional\n",
      " |        Additional attributes and their values\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Returns a string containing the printable representation of the object\n",
      " |  \n",
      " |  to_dgl_graph(self, self_loop: bool = False)\n",
      " |      Convert to DGL graph data instance\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dgl.DGLGraph\n",
      " |        Graph data for DGL\n",
      " |      self_loop: bool\n",
      " |        Whether to add self loops for the nodes, i.e. edges from nodes\n",
      " |        to themselves. Default to False.\n",
      " |      \n",
      " |      Note\n",
      " |      ----\n",
      " |      This method requires DGL to be installed.\n",
      " |  \n",
      " |  to_pyg_graph(self)\n",
      " |      Convert to PyTorch Geometric graph data instance\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      torch_geometric.data.Data\n",
      " |        Graph data for PyTorch Geometric\n",
      " |      \n",
      " |      Note\n",
      " |      ----\n",
      " |      This method requires PyTorch Geometric to be installed.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(testCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e51a61b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2, 30], edge_index=[2, 2], edge_attr=[2, 11])\n",
      "2\n",
      "False\n",
      "30\n",
      "11\n",
      "['x', 'edge_attr', 'edge_index']\n"
     ]
    }
   ],
   "source": [
    "testCO_pyg_graph = testCO.to_pyg_graph()\n",
    "\n",
    "print(testCO_pyg_graph)\n",
    "print(testCO_pyg_graph.num_nodes)\n",
    "print(testCO_pyg_graph.is_directed())\n",
    "print(testCO_pyg_graph.num_node_features)\n",
    "print(testCO_pyg_graph.num_edge_features)\n",
    "print(testCO_pyg_graph.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "526c3546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])}\n",
      "{'edge_attr': tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])}\n"
     ]
    }
   ],
   "source": [
    "testCO_dgl_graph = testCO.to_dgl_graph()\n",
    "print(testCO_dgl_graph.ndata)\n",
    "print(testCO_dgl_graph.edata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbb456e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphData(node_features=[3, 30], edge_index=[2, 4], edge_features=[4, 11])\n",
      "<class 'deepchem.feat.graph_data.GraphData'>\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[0 2 2 1]\n",
      " [2 0 1 2]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "testOCO = gen_smiles2graph(\"OCO\")\n",
    "print(testOCO)\n",
    "print(type(testOCO))\n",
    "print(testOCO.node_features)\n",
    "print(type(testOCO.node_features))\n",
    "print(testOCO.edge_index)\n",
    "print(type(testOCO.edge_index))\n",
    "print(testOCO.edge_features)\n",
    "print(type(testOCO.edge_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b0fb21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on GraphData in module deepchem.feat.graph_data object:\n",
      "\n",
      "class GraphData(builtins.object)\n",
      " |  GraphData(node_features: numpy.ndarray, edge_index: numpy.ndarray, edge_features: Union[numpy.ndarray, NoneType] = None, node_pos_features: Union[numpy.ndarray, NoneType] = None, **kwargs)\n",
      " |  \n",
      " |  GraphData class\n",
      " |  \n",
      " |  This data class is almost same as `torch_geometric.data.Data\n",
      " |  <https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data>`_.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  node_features: np.ndarray\n",
      " |    Node feature matrix with shape [num_nodes, num_node_features]\n",
      " |  edge_index: np.ndarray, dtype int\n",
      " |    Graph connectivity in COO format with shape [2, num_edges]\n",
      " |  edge_features: np.ndarray, optional (default None)\n",
      " |    Edge feature matrix with shape [num_edges, num_edge_features]\n",
      " |  node_pos_features: np.ndarray, optional (default None)\n",
      " |    Node position matrix with shape [num_nodes, num_dimensions].\n",
      " |  num_nodes: int\n",
      " |    The number of nodes in the graph\n",
      " |  num_node_features: int\n",
      " |    The number of features per node in the graph\n",
      " |  num_edges: int\n",
      " |    The number of edges in the graph\n",
      " |  num_edges_features: int, optional (default None)\n",
      " |    The number of features per edge in the graph\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> node_features = np.random.rand(5, 10)\n",
      " |  >>> edge_index = np.array([[0, 1, 2, 3, 4], [1, 2, 3, 4, 0]], dtype=np.int64)\n",
      " |  >>> edge_features = np.random.rand(5, 5)\n",
      " |  >>> global_features = np.random.random(5)\n",
      " |  >>> graph = GraphData(node_features, edge_index, edge_features, z=global_features)\n",
      " |  >>> graph\n",
      " |  GraphData(node_features=[5, 10], edge_index=[2, 5], edge_features=[5, 5], z=[5])\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, node_features: numpy.ndarray, edge_index: numpy.ndarray, edge_features: Union[numpy.ndarray, NoneType] = None, node_pos_features: Union[numpy.ndarray, NoneType] = None, **kwargs)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      node_features: np.ndarray\n",
      " |        Node feature matrix with shape [num_nodes, num_node_features]\n",
      " |      edge_index: np.ndarray, dtype int\n",
      " |        Graph connectivity in COO format with shape [2, num_edges]\n",
      " |      edge_features: np.ndarray, optional (default None)\n",
      " |        Edge feature matrix with shape [num_edges, num_edge_features]\n",
      " |      node_pos_features: np.ndarray, optional (default None)\n",
      " |        Node position matrix with shape [num_nodes, num_dimensions].\n",
      " |      kwargs: optional\n",
      " |        Additional attributes and their values\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Returns a string containing the printable representation of the object\n",
      " |  \n",
      " |  to_dgl_graph(self, self_loop: bool = False)\n",
      " |      Convert to DGL graph data instance\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dgl.DGLGraph\n",
      " |        Graph data for DGL\n",
      " |      self_loop: bool\n",
      " |        Whether to add self loops for the nodes, i.e. edges from nodes\n",
      " |        to themselves. Default to False.\n",
      " |      \n",
      " |      Note\n",
      " |      ----\n",
      " |      This method requires DGL to be installed.\n",
      " |  \n",
      " |  to_pyg_graph(self)\n",
      " |      Convert to PyTorch Geometric graph data instance\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      torch_geometric.data.Data\n",
      " |        Graph data for PyTorch Geometric\n",
      " |      \n",
      " |      Note\n",
      " |      ----\n",
      " |      This method requires PyTorch Geometric to be installed.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(testOCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d35404fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphData(node_features=[5, 30], edge_index=[2, 8], edge_features=[8, 11])\n",
      "<class 'deepchem.feat.graph_data.GraphData'>\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[3 4 4 0 4 2 4 1]\n",
      " [4 3 0 4 2 4 1 4]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# look up smiles strings of chemical structures: https://cactus.nci.nih.gov/chemical/structure\n",
    "testSO4 = gen_smiles2graph(\"O[S](O)(=O)=O\")\n",
    "print(testSO4)\n",
    "print(type(testSO4))\n",
    "print(testSO4.node_features)\n",
    "print(type(testSO4.node_features))\n",
    "print(testSO4.edge_index)\n",
    "print(type(testSO4.edge_index))\n",
    "print(testSO4.edge_features)\n",
    "print(type(testSO4.edge_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6109f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphData(node_features=[3, 30], edge_index=[2, 4], edge_features=[4, 11])\n",
      "<class 'deepchem.feat.graph_data.GraphData'>\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0. -1.  0.  1.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[2 0 0 1]\n",
      " [0 2 1 0]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# look up smiles strings of chemical structures: https://cactus.nci.nih.gov/chemical/structure\n",
    "# node features: [\"C\", \"N\", \"O\", \"F\", \"P\", \"S\", \"Cl\", \"Br\", \"I\"]\n",
    "testHCN = gen_smiles2graph(\"[O-][O+]=O\")\n",
    "print(testHCN)\n",
    "print(type(testHCN))\n",
    "print(testHCN.node_features)\n",
    "print(type(testHCN.node_features))\n",
    "print(testHCN.edge_index)\n",
    "print(type(testHCN.edge_index))\n",
    "print(testHCN.edge_features)\n",
    "print(type(testHCN.edge_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ce84ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eedc37d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to featurize datapoint 0, [Mo]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Al+3].[Al+3].[Mo].[Mo].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Ca+2].[Mg+2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Mg+2]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Ca+2].[OH-].[OH-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Ba+2].[Fe+3].[Fe+3].[Fe+3].[Fe+3].[Fe+3].[Fe+3].[Fe+3].[Fe+3].[Fe+3].[Fe+3].[Fe+3].[Fe+3].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [K+].[K+].[O-2].[O-2].[O-2].[Ti+4]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cd+2]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Cd+2].[OH-].[OH-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [OH-].[OH-].[Zn+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Re]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "[15:57:41] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [F-].[F-].[H+].[NH4+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [I-].[NH4+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, N. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Cl-].[Cu+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:57:42] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:57:42] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Lu+3].[Lu+3].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Gd+3].[Gd+3].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [O-2].[O-2].[O-2].[O-2].[O-2].[Pb+2].[Ti+4].[Zr+4]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:57:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:57:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:57:44] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [As]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [O-2].[O-2].[O-2].[Sb+3].[Sb+3]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Gd]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "[15:57:44] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Pb]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [I-].[Na+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:57:45] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:57:45] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [I-].[K+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:57:45] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:57:45] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Fe+3].[Fe+3].[Mo].[Mo].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:57:46] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Mg+2].[OH-].[OH-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Nd+3].[OH-].[OH-].[OH-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Te]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Dy+3].[Dy+3].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Y]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[Pr+3].[Pr+3].[Pr+3].[Pr+3].[Pr+3].[Pr+3]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Bi+3].[Bi+3].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [O-2].[O-2].[O-2].[Y+3].[Y+3]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cu]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [F-].[F-].[F-].[Nd+3]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Na+].[Na+].[O-2].[O-2].[O-2].[Ti+4]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [La+3].[La+3].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Hg]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Al+3].[F-].[F-].[F-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, O.[Mo].[NH4+].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Ce+3].[F-].[F-].[F-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cu+].[I-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, S. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [In+3].[In+3].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Fe+3].[K+].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, O.[K].[Li].[Ti]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Al+3].[O-2].[OH-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Zr]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Ca+2].[O-2].[O-2].[O-2].[Ti+4]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Al+3].[Al+3].[Ca+2].[Ca+2].[O-2].[O-2].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:57:55] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:57:55] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [H-].[H-].[Ti+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Fe+3].[Fe+3].[O-2].[O-2].[O-2].[O-2].[O-2].[Sr+2].[Sr+2]. Appending empty array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception message: tuple index out of range\n",
      "[15:57:55] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:57:55] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [H-].[H-].[Zr+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Mg+2].[Mg+2].[Nb+5].[Nb+5].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Hf]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Hf+4].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:57:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:57:57] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:57:57] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Cl-].[Li+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:57:57] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Cr].[F].[F].[F]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [F-].[F-].[Ni+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:57:58] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Cl-].[Cl-].[Sn+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:57:59] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, S.[Na+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cl-].[Cl-].[Cl-].[Cr+3]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, C.[Mo].[Mo]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cl-].[Cl-].[Cl-].[Cl-].[Cl-].[Cl-].[NH4+].[NH4+].[NH4+].[Rh+3]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [F-].[K+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Br-].[Na+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, O.O.O.O.O.O.O.[Cl-].[Cl-].[Cl-].[La+3]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Br-].[NH4+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:00] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Br-].[H+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [V]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Br-].[K+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cs+].[I-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:00] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Cl-].[Cl-].[Cl-].[Fe+3]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cl-].[Cl-].[Ni+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Sr]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Fe+3].[Fe+3].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cl-].[Cl-].[Co+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cl-].[Cl-].[Pd+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Na+].[SH-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:01] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Cl-].[Cl-].[Mg+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cd+2].[Cl-].[Cl-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:01] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Br-].[Br-].[Zn+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cl-].[Cl-].[Zn+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:01] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [F-].[Na+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:02] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Al+3].[F-].[K+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cl-].[NH4+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cl-].[K+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:02] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Cl-].[Na+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:03] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, S.[Mn]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, O.O.[Ba+2].[Cl-].[Cl-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cu+].[Cu+].[SH-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cs]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "[15:58:03] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:03] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, N.N.N.N.N.N.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.[Mo].[Mo].[Mo].[Mo].[Mo].[Mo].[Mo]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:04] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Br-].[Li+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Na+].[Na+].[SH-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [As+3].[As+3].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:05] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [La]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Li+].[OH-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:06] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [F-].[Li+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Al+3].[F-].[F-].[F-].[F-].[F-].[F-].[Li+].[Li+].[Li+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, N.N.[Cl-].[Cl-].[Pd+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Al+3].[F-].[F-].[F-].[F-].[F-].[F-].[Na+].[Na+].[Na+]. Appending empty array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, S.[Ni]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [S-2].[S-2].[Sn+4]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:08] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Cl-].[Cu+2].[Cu+2].[OH-].[OH-].[OH-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Mn]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [F-].[F-].[F-].[La+3]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Ta]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, O.O.O.O.[Cl-].[Cl-].[Mn+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Br-]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "[15:58:09] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:09] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:09] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Al+3].[Cl-].[Cl-].[Cl-].[Cl-].[Cl-].[Cl-].[Cl-].[Ti+4]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:10] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Au+3].[Cl-].[Cl-].[Cl-].[Cl-].[NH4+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cl-].[Cs+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cs+].[OH-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cl-].[Cl-].[Cl-].[In+3]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:10] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:10] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Cl-].[Cl-].[Cl-].[Cl-].[H+].[H+].[Pd+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:10] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Al+3].[O-2].[O-2].[O-2].[Y+3]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [I-].[I-].[I-].[Rh+3]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, C.[Nb]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Cr]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [O-2].[O-2].[O-2].[Sm+3].[Sm+3]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Co+2].[S-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, C.[V]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [P]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Nd+3].[Nd+3].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Al+3].[Al+3].[O-2].[O-2].[O-2].[O-2].[O-2].[Zn+2].[Zn+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Dy]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Co]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Al+3].[Cl-].[Cl-].[Cl-]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Se]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Fe]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [B]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [O-2].[O-2].[Pt+4]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Nd]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [O-2].[Pd+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Bi+3].[Bi+3].[S-2].[S-2].[S-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Ir]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Si]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, S.[Mo]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Sn]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "[15:58:16] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [Al+3].[Al+3].[Co+2].[Co+2].[O-2].[O-2].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Bi+3].[O-2].[O-2].[O-2].[O-2].[V]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, O.[Fe+3].[Fe+3].[O-2].[O-2].[O-2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, [Nb]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Be]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 0, [Au]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "[15:58:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:17] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, C. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "[15:58:19] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:19] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:19] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:20] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:22] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:25] WARNING: not removing hydrogen atom without neighbors\n",
      "Failed to featurize datapoint 0, [F-].[H+]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "Failed to featurize datapoint 0, N.N.[Cl-].[Cl-].[Pt+2]. Appending empty array\n",
      "Exception message: tuple index out of range\n",
      "[15:58:26] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:58:29] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "graph = []\n",
    "sol = []\n",
    "for i in range(len(soldata)):\n",
    "    graph.append(gen_smiles2graph(soldata.SMILES[i]))\n",
    "    sol.append(soldata.Solubility[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76b6ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, graphAll, solAll, transform=None, target_transform=None):\n",
    "        self.graphInstances = graphAll\n",
    "        self.solInstances = solAll\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphInstances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graphInstance = self.graphInstances[idx]\n",
    "        solInstance = self.solInstances[idx]\n",
    "        if self.transform:\n",
    "            graphInstance = self.transform(graphInstance)\n",
    "        if self.target_transform:\n",
    "            solInstance = self.target_transform(solInstance)\n",
    "        return graphInstance, solInstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6881b9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdcd5500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998\n",
      "998\n",
      "7986\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(graphAll=graph, solAll=sol)\n",
    "\n",
    "# batch_size=1 was original default - 100 was used in bondnet paper\n",
    "dataloader = data.DataLoader(dataset, batch_size=1,\n",
    "                        shuffle=True, num_workers=cores)\n",
    "# print(len(dataloader))\n",
    "# print(type(dataloader))\n",
    "\n",
    "test_data_size = int(0.1 * len(dataloader))\n",
    "val_data_size = int(0.1 * len(dataloader))\n",
    "train_data_size = len(dataloader) - 2 * int(0.1 * len(dataloader))\n",
    "\n",
    "# test_data_size = 20\n",
    "# val_data_size = 20\n",
    "# train_data_size = 160\n",
    "\n",
    "# test_data_size = 200\n",
    "# val_data_size = 200\n",
    "# train_data_size = len(dataloader) - 400\n",
    "\n",
    "print(test_data_size)\n",
    "print(val_data_size)\n",
    "print(train_data_size)\n",
    "\n",
    "test_data, val_data, train_data = data.random_split(dataloader, [test_data_size, val_data_size, train_data_size], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "test_data_loader = data.DataLoader(test_data, batch_size=1, shuffle=True, num_workers=cores)\n",
    "val_data_loader = data.DataLoader(val_data, batch_size=1, shuffle=True, num_workers=cores)\n",
    "train_data_loader = data.DataLoader(train_data, batch_size=1, shuffle=True, num_workers=cores)\n",
    "# print(test_data)\n",
    "# print(val_data)\n",
    "# print(train_data)\n",
    "# print(train_data.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54ab60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create \"zeroth\" FCNN with 1 fully connected layer\n",
    "# condense node features from 30 to 24\n",
    "# dilate edge features from 11 to 24\n",
    "# see Table S4 BDNCM input feature embedding size 24: https://www.rsc.org/suppdata/d0/sc/d0sc05251e/d0sc05251e1.pdf\n",
    "class InitialEmbedding(torch.nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(0)\n",
    "        self.fc_initial_embedding = nn.Linear(c_in, c_out)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        features = self.fc(features)\n",
    "        features = F.relu(features)\n",
    "        \n",
    "        return features\n",
    "\n",
    "# neural network with two fully connected layers\n",
    "class FCNN(torch.nn.Module):\n",
    "    # c_in1 = 24, c_out1 = 256, c_out2 = 24\n",
    "    def __init__(self, c_in1, c_out1, c_out2):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(0)\n",
    "        self.fc1 = nn.Linear(c_in1, c_out1)\n",
    "        torch.manual_seed(0)\n",
    "        self.fc2 = nn.Linear(c_out1, c_out2)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        # print(\"input 2 layer FCNN features: \", features)\n",
    "        features = self.fc1(features)\n",
    "        # print(\"after 1 linear layer updated features: \", features)\n",
    "        features = F.relu(features)\n",
    "        # print(\"after ReLu updated features: \", features)\n",
    "        features = self.fc2(features)\n",
    "        \n",
    "        # print(\"after 2 linear layers updated features: \", features)\n",
    "        \n",
    "        return features\n",
    "\n",
    "# implementation of equation 5 in bondnet paper \n",
    "# https://pubs.rsc.org/en/content/articlepdf/2021/sc/d0sc05251e\n",
    "class NodeFeatures(torch.nn.Module):\n",
    "    # c_in1 = 24, c_out1 = 24, c_out2 = 24\n",
    "    def __init__(self, c_in1, c_out1, c_out2):\n",
    "        super().__init__()\n",
    "        # self.fc_initial_embedding = InitialEmbedding(c_in=30, c_out=24)\n",
    "        self.FCNN_one = FCNN(c_in1=c_in1, c_out1=c_out1, c_out2=c_out2)\n",
    "        self.FCNN_two = FCNN(c_in1=c_in1, c_out1=c_out1, c_out2=c_out2)\n",
    "        \n",
    "    def forward(self, node_features, edge_index, edge_features):\n",
    "        sigmoidFunction = torch.nn.Sigmoid()\n",
    "        \n",
    "        original_node_features = node_features.detach().clone()\n",
    "        \n",
    "        epsilon = 1e-7\n",
    "        \n",
    "        for i in range(len(node_features)):\n",
    "            # DOUBLE CHECK WITH DAS\n",
    "            # intermediate_node_feature = self.FCNN_one(node_features[i].T)\n",
    "            intermediate_node_feature = self.FCNN_one(original_node_features[i].T)\n",
    "            \n",
    "            other_nodes_indices = []\n",
    "            other_edges_indices = []\n",
    "            \n",
    "            other_edges_numerators = []\n",
    "            other_edges_denominator = epsilon\n",
    "            \n",
    "            '''\n",
    "            print(\"node_features[i].T: \", node_features[i].T)\n",
    "            print(\"node_features[i].T.size: \", node_features[i].T.size())\n",
    "            \n",
    "            print(\"intermediate_node_feature: \", intermediate_node_feature)\n",
    "            print(\"intermediate_node_feature.size: \", intermediate_node_feature.size())\n",
    "            '''\n",
    "            \n",
    "            for j in range(len(edge_index[0])):\n",
    "                if edge_index[0][j] == i:\n",
    "                    other_nodes_indices.append(int(edge_index[1][j]))\n",
    "                    other_edges_indices.append(j)\n",
    "                if edge_index[1][j] == i:\n",
    "                    other_nodes_indices.append(int(edge_index[0][j]))\n",
    "                    other_edges_indices.append(j)\n",
    "            \n",
    "            '''\n",
    "            print(\"current node index: \", i)\n",
    "            print(\"other_nodes_indices: \", other_nodes_indices)\n",
    "            print(\"other_edges_indices: \", other_edges_indices)\n",
    "            '''\n",
    "            \n",
    "            for other_edge_index in other_edges_indices:\n",
    "                # print(\"SIGMOID ALERT TEST TEST TEST: \", sigmoidFunction(edge_features[other_edge_index]))\n",
    "                other_edges_numerators.append(sigmoidFunction(edge_features[other_edge_index]))\n",
    "                other_edges_denominator += sigmoidFunction(edge_features[other_edge_index])\n",
    "                \n",
    "            # print(\"other_edges_numerators: \", other_edges_numerators)\n",
    "            # print(\"other_edges_denominator: \", other_edges_denominator)\n",
    "            \n",
    "            for other_edge_numerator, other_node_index in zip(other_edges_numerators, other_nodes_indices):\n",
    "                edge_hat = other_edge_numerator/other_edges_denominator\n",
    "                # DOUBLE CHECK WITH DAS\n",
    "                # other_node_updated = self.FCNN_two(node_features[other_node_index].T) \n",
    "                other_node_updated = self.FCNN_two(original_node_features[other_node_index].T) \n",
    "                intermediate_node_feature += edge_hat * other_node_updated\n",
    "                \n",
    "                # print(\"edge_hat: \", edge_hat)\n",
    "                '''\n",
    "                print(\"node_features[other_node_index].T: \", node_features[other_node_index].T)\n",
    "                print(\"node_features[other_node_index].T.size: \", node_features[other_node_index].T.size())\n",
    "                print(\"other_node_updated: \", other_node_updated)\n",
    "                print(\"other_node_updated.size: \", other_node_updated.size())\n",
    "                '''\n",
    "                \n",
    "            print(\"intermediate_node_feature: \", intermediate_node_feature)\n",
    "            print(\"intermediate_node_feature.size: \", intermediate_node_feature.size())\n",
    "                \n",
    "            '''\n",
    "            print(\"reLuOutput: \", F.relu(intermediate_node_feature))\n",
    "            print(\"reLuOutput.size: \", F.relu(intermediate_node_feature).size())\n",
    "            print(\"original_node_features[i].T\", original_node_features[i].T)\n",
    "            print(\"original_node_features[i].T.size\", original_node_features[i].T.size())\n",
    "            print(\"calculated updated node_features[i]: \", (original_node_features[i].T + F.relu(intermediate_node_feature)).T)\n",
    "            print(\"calculated updated node_features[i].size(): \", (original_node_features[i].T + F.relu(intermediate_node_feature)).T.size())\n",
    "            '''\n",
    "            \n",
    "            # UPDATE TO INCLUDE THIS AT SOME POINT\n",
    "            # intermediate_node_feature --> batch normalization --> drop out --> then ReLu\n",
    "            # should I use batch norm 1D and what should my feature size be at this point?\n",
    "            '''\n",
    "            batchNorm1dLayer = nn.BatchNorm1d(intermediate_node_feature.size(dim=0))\n",
    "            dropoutLayer = nn.Dropout(p=0.1)\n",
    "            \n",
    "            intermediate_node_feature = batchNorm1dLayer(torch.reshape(intermediate_node_feature, (1, intermediate_node_feature.size(dim=0))))\n",
    "            intermediate_node_feature = torch.reshape(intermediate_node_feature, (-1,))\n",
    "            intermediate_node_feature = dropoutLayer(intermediate_node_feature)\n",
    "            '''\n",
    "            \n",
    "            instanceNorm1dLayer = nn.InstanceNorm1d(intermediate_node_feature.size(dim=0))\n",
    "            dropoutLayer = nn.Dropout(p=0.1)\n",
    "            \n",
    "            intermediate_node_feature = instanceNorm1dLayer(torch.reshape(intermediate_node_feature, (1, intermediate_node_feature.size(dim=0))))\n",
    "            intermediate_node_feature = torch.reshape(intermediate_node_feature, (-1,))\n",
    "            intermediate_node_feature = dropoutLayer(intermediate_node_feature)\n",
    "            \n",
    "            # node_features[i] = F.relu(intermediate_node_feature).T\n",
    "            node_features[i] = (original_node_features[i].T + F.relu(intermediate_node_feature)).T\n",
    "            \n",
    "            print(\"actually updated node_features[i]: \", node_features[i])\n",
    "            print(\"actually updated node_features[i].size(): \", node_features[i].size())\n",
    "            print(\"********** NODE UPDATED SUCCESSFULLY ****************\")\n",
    "            \n",
    "        return node_features\n",
    "        \n",
    "# implementation of equation 4 in bondnet paper\n",
    "# https://pubs.rsc.org/en/content/articlepdf/2021/sc/d0sc05251e\n",
    "class EdgeFeatures(torch.nn.Module):\n",
    "    # c_in1 = 24, c_out1 = 24, c_out2 = 24\n",
    "    def __init__(self, c_in1, c_out1, c_out2):\n",
    "        super().__init__()\n",
    "        # self.fc_initial_embedding = InitialEmbedding(c_in=11, c_out=24)\n",
    "        self.FCNN_one = FCNN(c_in1=c_in1, c_out1=c_out1, c_out2=c_out2)\n",
    "        self.FCNN_two = FCNN(c_in1=c_in1, c_out1=c_out1, c_out2=c_out2)\n",
    "        \n",
    "    def forward(self, node_features, edge_index, edge_features):\n",
    "        original_edge_features = edge_features.detach().clone()\n",
    "        \n",
    "        for i in range(len(edge_index[0])):\n",
    "            # summing node features involved in the given edge and transforming them\n",
    "            firstNodeIndex = int(edge_index[0][i])\n",
    "            secondNodeIndex = int(edge_index[1][i])\n",
    "            node_features_sum = node_features[firstNodeIndex] + node_features[secondNodeIndex]\n",
    "            intermediate_node_features = self.FCNN_one(node_features_sum.T)\n",
    "            \n",
    "            print(\"firstNodeIndex: \", firstNodeIndex)\n",
    "            print(\"secondNodeIndex: \", secondNodeIndex)\n",
    "            print(\"node_features[firstNodeIndex]: \", node_features[firstNodeIndex])\n",
    "            print(\"node_features[secondNodeIndex]: \", node_features[secondNodeIndex])\n",
    "            print(\"node_features_sum: \", node_features_sum)\n",
    "            print(\"node_features_sum.size: \", node_features_sum.size())\n",
    "            print(\"node_features_sum.T: \", node_features_sum.T)\n",
    "            print(\"node_features_sum.T.size: \", node_features_sum.T.size())\n",
    "            print(\"intermediate_node_features: \", intermediate_node_features)\n",
    "            print(\"intermediate_node_features.size: \", intermediate_node_features.size())\n",
    "            \n",
    "            # transforming the features of the given edge \n",
    "            intermediate_edge_feature = self.FCNN_two(edge_features[i].T)\n",
    "            \n",
    "            print(\"edge_features index: \", i)\n",
    "            print(\"edge_features: \", edge_features[i])\n",
    "            print(\"edge_features.size: \", edge_features[i].size())\n",
    "            print(\"edge_features.T: \", edge_features[i].T)\n",
    "            print(\"edge_features.T.size(): \", edge_features[i].T.size())\n",
    "            print(\"intermediate_edge_feature: \", intermediate_edge_feature)\n",
    "            print(\"intermediate_edge_feature.size: \", intermediate_edge_feature.size())\n",
    "            print(\"intermediate_edge_feature.size dim 0: \", intermediate_edge_feature.size(dim=0))\n",
    "\n",
    "            # merging node features with features of the given edge\n",
    "            \n",
    "            # UPDATE TO INCLUDE THIS AT SOME POINT\n",
    "            # intermediate_node_features + intermediate_edge_feature --> batch normalization --> drop out --> then ReLu\n",
    "            \n",
    "            intermediate_features_relu_input = intermediate_node_features + intermediate_edge_feature\n",
    "            \n",
    "            instanceNorm1dLayer = nn.InstanceNorm1d(intermediate_features_relu_input.size(dim=0))\n",
    "            dropoutLayer = nn.Dropout(p=0.1)\n",
    "            \n",
    "            intermediate_features_relu_input = instanceNorm1dLayer(torch.reshape(intermediate_features_relu_input, (1, intermediate_features_relu_input.size(dim=0))))\n",
    "            intermediate_features_relu_input = torch.reshape(intermediate_features_relu_input, (-1,))                                                              \n",
    "            intermediate_features_relu_input = dropoutLayer(intermediate_features_relu_input)\n",
    "            \n",
    "            intermediate_features = F.relu(intermediate_features_relu_input)\n",
    "            \n",
    "            print(\"intermediate_features: \", intermediate_features)\n",
    "            print(\"intermediate_features.size: \", intermediate_features.size())\n",
    "            print(\"original_edge_features[i].T: \", original_edge_features[i].T)\n",
    "            print(\"calculated updated edge_features[i]: \", (original_edge_features[i].T + intermediate_features).T)\n",
    "            \n",
    "            # updating edge features\n",
    "            edge_features[i] = (original_edge_features[i].T + intermediate_features).T\n",
    "            \n",
    "            print(\"actually updated edge_features[i]: \", edge_features[i])\n",
    "            print(\"********** EDGE UPDATED SUCCESSFULLY ****************\")\n",
    "            \n",
    "        return edge_features\n",
    "    \n",
    "class Graph2Graph(torch.nn.Module):\n",
    "    def __init__(self, c_in1, c_out1, c_out2):\n",
    "        super().__init__()\n",
    "        self.NodeFeaturesConvolution = NodeFeatures(c_in1, c_out1, c_out2)\n",
    "        self.EdgeFeaturesConvolution = EdgeFeatures(c_in1, c_out1, c_out2)\n",
    "        \n",
    "    def forward(self, node_features, edge_index, edge_features):\n",
    "        node_features = self.NodeFeaturesConvolution\n",
    "        edge_features = self.EdgeFeaturesConvolution\n",
    "        \n",
    "        return node_features, edge_features\n",
    "    \n",
    "class Features_Set2Set():\n",
    "    def __init__(self, initial_dim_out):\n",
    "        self.node_s2s = Set2Set(initial_dim_out, 6, 3)\n",
    "        self.edge_s2s = Set2Set(initial_dim_out, 6, 3)\n",
    "    \n",
    "    def transform_then_concat(self, node_features, edge_index, edge_features):\n",
    "        deepchem_graph = dc.GraphData(node_features, edge_index, edge_features)\n",
    "        dgl_graph = deepchem_graph.to_dgl_graph()\n",
    "        node_features_transformed = self.node_s2s(dgl_graph, node_features)\n",
    "        edge_features_transformed = self.edge_s2s(dgl_graph, edge_features)\n",
    "        \n",
    "        return torch.cat(node_features_transformed, edge_features_transformed)\n",
    "\n",
    "class Graph2Property(torch.nn.Module):\n",
    "    # c_in1 = 24, c_out1 = 256, c_out2 = 128, c_out3 = 64, c_out4 = 1\n",
    "    def __init__(self, c_in1, c_out1, c_out2, c_out3, c_out4):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(c_in1, c_out1)\n",
    "        self.fc2 = nn.Linear(c_out1, c_out2)\n",
    "        self.fc3 = nn.Linear(c_out2, c_out3)\n",
    "        self.fc4 = nn.Linear(c_out3, c_out4)\n",
    "\n",
    "    def forward(self, features):\n",
    "        features = self.fc1(features)\n",
    "        features = F.relu(features)\n",
    "        features = self.fc2(features)\n",
    "        features = F.relu(features)\n",
    "        features = self.fc3(features)\n",
    "        features = F.relu(features)\n",
    "        features = self.fc4(features)\n",
    "        \n",
    "        return features\n",
    "        \n",
    "class GraphNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, nodes_initial_dim_in=30, edges_initial_dim_in=11, initial_dim_out=24, g2g_hidden_dim=256, g2p_dim_1=256, g2p_dim_2=128, g2p_dim_3=64):\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "        self.nodes_initial_embedding = InitialEmbedding(nodes_initial_dim_in, initial_dim_out)\n",
    "        self.edges_initial_embedding = InitialEmbedding(edges_initial_dim_in, initial_dim_out)\n",
    "        self.g2g_module = Graph2Graph(initial_dim_out, g2g_hidden_dim, initial_dim_out)\n",
    "        self.features_set2set = Features_Set2Set(initial_dim_out)\n",
    "        self.g2p_module = Graph2Property(initial_dim_out, g2p_dim_1, g2p_dim_2, g2p_dim_3, 1)\n",
    "        \n",
    "    def forward(self, graph_instance, g2g_num=4):\n",
    "        node_features = graph_instance.node_features \n",
    "        edge_index = graph_instance.edge_index\n",
    "        edge_features = graph_instance.edge_features\n",
    "        \n",
    "        node_features_updated = self.nodes_initial_embedding(node_features)\n",
    "        edge_features_updated = self.edges_initial_embedding(edge_features)\n",
    "        \n",
    "        for i in range(g2g_num):\n",
    "            node_features_updated, edge_features_updated = self.g2g_module(node_features, edge_index, edge_features)\n",
    "            \n",
    "        features_concatenated = Features_Set2Set(node_features_updated, edge_index, edge_features_updated)\n",
    "        \n",
    "        predicted_value = self.g2p_module(features_concatenated)\n",
    "        \n",
    "        return predicted_value\n",
    "\n",
    "model = GraphNeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a15a87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIT TESTING EDGE UPDATE\n",
    "\n",
    "node_features = torch.Tensor([[0, 1, 0],\n",
    "                          [0, 1, 1],\n",
    "                          [1, 0, 0]])\n",
    "edge_index = torch.Tensor([[2, 0, 0, 1],\n",
    "                       [0, 2, 1, 0]])\n",
    "edge_features = torch.Tensor([[1, 0, 1],\n",
    "                         [1, 0, 1],\n",
    "                         [0, 1, 0],\n",
    "                         [0, 1, 0]])\n",
    "\n",
    "def linear_layer(weights, biases, features):\n",
    "    # (3 x 3 x (1 x 3).T + (1 x 3).T).T returns 3 x 1\n",
    "    return (np.dot(weights, features.T) + biases.T).T\n",
    "\n",
    "def fcnn(weights, biases, features):\n",
    "    features = linear_layer(weights, biases, features)\n",
    "    features = F.relu(torch.Tensor(features)).numpy()\n",
    "    features = linear_layer(weights, biases, features)\n",
    "    return features\n",
    "\n",
    "weights = np.array([[1., 0., 0.], \n",
    "                    [0., 1., 0.],\n",
    "                    [0., 0., 1.]])\n",
    "\n",
    "biases = np.array([0., 0., 0.])\n",
    "\n",
    "edge_features = np.array([[1, 0, 1],\n",
    "                          [1, 0, 1],\n",
    "                          [0, 1, 0],\n",
    "                          [0, 1, 0]])\n",
    "\n",
    "# phi 2 test\n",
    "phi_2_output = []\n",
    "\n",
    "for edge in edge_features:\n",
    "    phi_2_output.append(fcnn(weights, biases, edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ede4683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIT TESTING EDGE UPDATE\n",
    "\n",
    "def linear_layer(weights, biases, features):\n",
    "    # (3 x 3 x (1 x 3).T + (1 x 3).T).T returns 3 x 1\n",
    "    return (np.dot(weights, features.T) + biases.T).T\n",
    "\n",
    "def fcnn(weights, biases, features):\n",
    "    features = linear_layer(weights, biases, features)\n",
    "    features = F.relu(torch.Tensor(features)).numpy()\n",
    "    features = linear_layer(weights, biases, features)\n",
    "    return features\n",
    "\n",
    "weights = np.array([[1., 0., 0.], \n",
    "                    [0., 1., 0.],\n",
    "                    [0., 0., 1.]])\n",
    "\n",
    "biases = np.array([0., 0., 0.])\n",
    "\n",
    "node_features = np.array([[0, 1, 0],\n",
    "                          [0, 1, 1],\n",
    "                          [1, 0, 0]])\n",
    "\n",
    "# phi 1 test\n",
    "phi_1_output = []\n",
    "\n",
    "for i in range(len(edge_index[0])):\n",
    "    # summing node features involved in the given edge and transforming them\n",
    "    firstNodeIndex = int(edge_index[0][i])\n",
    "    secondNodeIndex = int(edge_index[1][i])\n",
    "    node_features_sum = node_features[firstNodeIndex] + node_features[secondNodeIndex]\n",
    "    phi_1_output.append(fcnn(weights, biases, node_features_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "976a3023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0.]\n",
      " [1. 1. 0.]\n",
      " [0. 2. 1.]\n",
      " [0. 2. 1.]]\n",
      "[[1. 0. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n",
      "[[3. 1. 2.]\n",
      " [3. 1. 2.]\n",
      " [0. 4. 1.]\n",
      " [0. 4. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# UNIT TESTING EDGE UPDATE\n",
    "\n",
    "phi_1_np_output = np.array(phi_1_output)\n",
    "phi_2_np_output = np.array(phi_2_output)\n",
    "\n",
    "print(phi_1_np_output)\n",
    "print(phi_2_np_output)\n",
    "\n",
    "updated_edge_features = edge_features + F.relu(torch.Tensor(phi_1_np_output + phi_2_np_output)).numpy()\n",
    "\n",
    "print(updated_edge_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa1c4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIT TESTING NODE UPDATE\n",
    "\n",
    "def linear_layer(weights, biases, features):\n",
    "    # (3 x 3 x (1 x 3).T + (1 x 3).T).T returns 3 x 1\n",
    "    return (np.dot(weights, features.T) + biases.T).T\n",
    "\n",
    "def fcnn(weights, biases, features):\n",
    "    features = linear_layer(weights, biases, features)\n",
    "    features = F.relu(torch.Tensor(features)).numpy()\n",
    "    features = linear_layer(weights, biases, features)\n",
    "    return features\n",
    "\n",
    "weights = np.array([[1., 0., 0.], \n",
    "                    [0., 1., 0.],\n",
    "                    [0., 0., 1.]])\n",
    "\n",
    "biases = np.array([0., 0., 0.])\n",
    "\n",
    "node_features = np.array([[0, 1, 0],\n",
    "                          [0, 1, 1],\n",
    "                          [1, 0, 0]])\n",
    "\n",
    "original_node_features = node_features.copy()\n",
    "\n",
    "edge_index = np.array([[2, 0, 0, 1],\n",
    "                       [0, 2, 1, 0]])\n",
    "edge_features = np.array([[1, 0, 1],\n",
    "                         [1, 0, 1],\n",
    "                         [0, 1, 0],\n",
    "                         [0, 1, 0]])\n",
    "\n",
    "# phi 4 test\n",
    "phi_4_output = []\n",
    "\n",
    "for node in original_node_features:\n",
    "    phi_4_output.append(fcnn(weights, biases, node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1843a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate_node_feature_np [0.59384549 1.59384549 0.40615451]\n",
      "intermediate_node_feature_torch_tensor tensor([0.5938, 1.5938, 0.4062])\n",
      "F RELU TT NOT TRANSPOSED:  tensor([0.5938, 1.5938, 0.4062])\n",
      "F RELU TT TRANSPOSED:  tensor([0.5938, 1.5938, 0.4062])\n",
      "F RELU TT TRANSPOSED CAST TO NUMPY:  [0.5938455 1.5938455 0.4061545]\n",
      "[0.59384549 2.59384549 0.40615451]\n",
      "********** NODE UPDATED SUCCESSFULLY ****************\n",
      "intermediate_node_feature_np [0.         1.99999994 1.        ]\n",
      "intermediate_node_feature_torch_tensor tensor([0., 2., 1.])\n",
      "F RELU TT NOT TRANSPOSED:  tensor([0., 2., 1.])\n",
      "F RELU TT TRANSPOSED:  tensor([0., 2., 1.])\n",
      "F RELU TT TRANSPOSED CAST TO NUMPY:  [0. 2. 1.]\n",
      "[0. 3. 2.]\n",
      "********** NODE UPDATED SUCCESSFULLY ****************\n",
      "intermediate_node_feature_np [1.         0.99999988 0.        ]\n",
      "intermediate_node_feature_torch_tensor tensor([1.0000, 1.0000, 0.0000])\n",
      "F RELU TT NOT TRANSPOSED:  tensor([1.0000, 1.0000, 0.0000])\n",
      "F RELU TT TRANSPOSED:  tensor([1.0000, 1.0000, 0.0000])\n",
      "F RELU TT TRANSPOSED CAST TO NUMPY:  [1.        0.9999999 0.       ]\n",
      "[2.         0.99999988 0.        ]\n",
      "********** NODE UPDATED SUCCESSFULLY ****************\n"
     ]
    }
   ],
   "source": [
    "# UNIT TESTING NODE UPDATE\n",
    "\n",
    "def linear_layer(weights, biases, features):\n",
    "    # (3 x 3 x (1 x 3).T + (1 x 3).T).T returns 3 x 1\n",
    "    return (np.dot(weights, features.T) + biases.T).T\n",
    "\n",
    "def fcnn(weights, biases, features):\n",
    "    features = linear_layer(weights, biases, features)\n",
    "    features = F.relu(torch.Tensor(features)).numpy()\n",
    "    features = linear_layer(weights, biases, features)\n",
    "    return features\n",
    "\n",
    "weights = np.array([[1., 0., 0.], \n",
    "                    [0., 1., 0.],\n",
    "                    [0., 0., 1.]])\n",
    "\n",
    "biases = np.array([0., 0., 0.])\n",
    "\n",
    "# phi 5 test\n",
    "phi_5_output = []\n",
    "\n",
    "sigmoidFunction = torch.nn.Sigmoid()     \n",
    "epsilon = 1e-7\n",
    "\n",
    "for i in range(len(node_features)):\n",
    "    other_nodes_indices = []\n",
    "    other_edges_indices = []\n",
    "\n",
    "    other_edges_numerators = []\n",
    "    # DOUBLE CHECK WITH DAS (SEE BONDNET PAPER EQUATION 6 AND COMMENT BELOW)\n",
    "    # normally, we can't add a scalar to a vector - what's happening here? \n",
    "    other_edges_denominator = epsilon\n",
    "\n",
    "    for j in range(len(edge_index[0])):\n",
    "        if edge_index[0][j] == i:\n",
    "            other_nodes_indices.append(int(edge_index[1][j]))\n",
    "            other_edges_indices.append(j)\n",
    "        if edge_index[1][j] == i:\n",
    "            other_nodes_indices.append(int(edge_index[0][j]))\n",
    "            other_edges_indices.append(j)\n",
    "    \n",
    "    for other_edge_index in other_edges_indices:\n",
    "        tensorInput = torch.from_numpy(edge_features[other_edge_index])\n",
    "        other_edges_numerators.append(sigmoidFunction(tensorInput).numpy())\n",
    "        other_edges_denominator += sigmoidFunction(tensorInput)\n",
    "    \n",
    "    other_edges_denominator = other_edges_denominator.numpy()\n",
    "    \n",
    "    intermediate_node_feature = phi_4_output[i]\n",
    "\n",
    "    for other_edge_numerator, other_node_index in zip(other_edges_numerators, other_nodes_indices):\n",
    "        edge_hat = other_edge_numerator/other_edges_denominator\n",
    "        # DOUBLE CHECK WITH DAS\n",
    "        # other_node_updated = self.FCNN_two(node_features[other_node_index].T) \n",
    "        other_node_updated = fcnn(weights, biases, original_node_features[other_node_index].T)\n",
    "        # print(\"other_node_updated/phi_5_output: \", other_node_updated)\n",
    "        \n",
    "        phi_5_output.append(other_node_updated)\n",
    "        \n",
    "        # print(\"edge_hat: \", edge_hat)\n",
    "        \n",
    "        intermediate_node_feature += edge_hat * other_node_updated\n",
    "\n",
    "    # print(\"other_edges_numerators: \", other_edges_numerators)\n",
    "    # print(\"other_edges_denominator: \", other_edges_denominator)\n",
    "    \n",
    "    print(\"intermediate_node_feature_np\", intermediate_node_feature)\n",
    "    \n",
    "    intermediate_node_feature_tt = torch.Tensor(intermediate_node_feature)\n",
    "    \n",
    "    print(\"intermediate_node_feature_torch_tensor\", intermediate_node_feature_tt)\n",
    "    \n",
    "    '''\n",
    "    print(\"reLuOutput: \", F.relu(intermediate_node_feature))\n",
    "    print(\"reLuOutput.size: \", F.relu(intermediate_node_feature).size())\n",
    "    print(\"original_node_features[i].T\", original_node_features[i].T)\n",
    "    print(\"original_node_features[i].T.size\", original_node_features[i].T.size())\n",
    "    print(\"calculated updated node_features[i]: \", (original_node_features[i].T + F.relu(intermediate_node_feature)).T)\n",
    "    print(\"calculated updated node_features[i].size(): \", (original_node_features[i].T + F.relu(intermediate_node_feature)).T.size())\n",
    "    '''\n",
    "    \n",
    "    intermediate_node_feature_tt_relu = F.relu(intermediate_node_feature_tt)\n",
    "    \n",
    "    print(\"F RELU TT NOT TRANSPOSED: \", intermediate_node_feature_tt_relu)\n",
    "    print(\"F RELU TT TRANSPOSED: \", intermediate_node_feature_tt_relu.T)\n",
    "    print(\"F RELU TT TRANSPOSED CAST TO NUMPY: \", intermediate_node_feature_tt_relu.T.numpy())\n",
    "    \n",
    "    # print(\"BEFORE node_features[i]: \", node_features[i])\n",
    "    \n",
    "    # node_features[i] = (intermediate_node_feature_tt_relu.T).numpy()\n",
    "\n",
    "    # node_features[i] = original_node_features[i].T + (F.relu(torch.Tensor(intermediate_node_feature)).T).numpy()\n",
    "\n",
    "    # print(\"actually updated node_features[i]: \", node_features[i])\n",
    "    node_feature_updated = original_node_features[i].T + intermediate_node_feature_tt_relu.T.numpy()\n",
    "    print(node_feature_updated)\n",
    "    print(\"********** NODE UPDATED SUCCESSFULLY ****************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1dea7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.59384549 1.59384549 0.40615451]\n",
      " [0.         1.99999994 1.        ]\n",
      " [1.         0.99999988 0.        ]]\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# UNIT TESTING NODE UPDATE\n",
    "\n",
    "phi_4_np_output = np.array(phi_4_output)\n",
    "phi_5_np_output = np.array(phi_5_output)\n",
    "\n",
    "print(phi_4_np_output)\n",
    "print(phi_5_np_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df344aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_features:  tensor([[0., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 0.]])\n",
      "edge_index:  tensor([[2., 0., 0., 1.],\n",
      "        [0., 2., 1., 0.]])\n",
      "edge_features:  tensor([[1., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n",
      "intermediate_node_feature:  tensor([0.5938, 1.5938, 0.4062])\n",
      "intermediate_node_feature.size:  torch.Size([3])\n",
      "actually updated node_features[i]:  tensor([0.0000, 2.5543, 0.0000])\n",
      "actually updated node_features[i].size():  torch.Size([3])\n",
      "********** NODE UPDATED SUCCESSFULLY ****************\n",
      "intermediate_node_feature:  tensor([0., 2., 1.])\n",
      "intermediate_node_feature.size:  torch.Size([3])\n",
      "actually updated node_features[i]:  tensor([0.0000, 2.3608, 1.0000])\n",
      "actually updated node_features[i].size():  torch.Size([3])\n",
      "********** NODE UPDATED SUCCESSFULLY ****************\n",
      "intermediate_node_feature:  tensor([1.0000, 1.0000, 0.0000])\n",
      "intermediate_node_feature.size:  torch.Size([3])\n",
      "actually updated node_features[i]:  tensor([1.7857, 0.7857, 0.0000])\n",
      "actually updated node_features[i].size():  torch.Size([3])\n",
      "********** NODE UPDATED SUCCESSFULLY ****************\n",
      "firstNodeIndex:  2\n",
      "secondNodeIndex:  0\n",
      "node_features[firstNodeIndex]:  tensor([1.7857, 0.7857, 0.0000])\n",
      "node_features[secondNodeIndex]:  tensor([0.0000, 2.5543, 0.0000])\n",
      "node_features_sum:  tensor([1.7857, 3.3399, 0.0000])\n",
      "node_features_sum.size:  torch.Size([3])\n",
      "node_features_sum.T:  tensor([1.7857, 3.3399, 0.0000])\n",
      "node_features_sum.T.size:  torch.Size([3])\n",
      "intermediate_node_features:  tensor([1.7857, 3.3399, 0.0000])\n",
      "intermediate_node_features.size:  torch.Size([3])\n",
      "edge_features index:  0\n",
      "edge_features:  tensor([1., 0., 1.])\n",
      "edge_features.size:  torch.Size([3])\n",
      "edge_features.T:  tensor([1., 0., 1.])\n",
      "edge_features.T.size():  torch.Size([3])\n",
      "intermediate_edge_feature:  tensor([1., 0., 1.])\n",
      "intermediate_edge_feature.size:  torch.Size([3])\n",
      "intermediate_edge_feature.size dim 0:  3\n",
      "intermediate_features:  tensor([0.4568, 1.0736, 0.0000])\n",
      "intermediate_features.size:  torch.Size([3])\n",
      "original_edge_features[i].T:  tensor([1., 0., 1.])\n",
      "calculated updated edge_features[i]:  tensor([1.4568, 1.0736, 1.0000])\n",
      "actually updated edge_features[i]:  tensor([1.4568, 1.0736, 1.0000])\n",
      "********** EDGE UPDATED SUCCESSFULLY ****************\n",
      "firstNodeIndex:  0\n",
      "secondNodeIndex:  2\n",
      "node_features[firstNodeIndex]:  tensor([0.0000, 2.5543, 0.0000])\n",
      "node_features[secondNodeIndex]:  tensor([1.7857, 0.7857, 0.0000])\n",
      "node_features_sum:  tensor([1.7857, 3.3399, 0.0000])\n",
      "node_features_sum.size:  torch.Size([3])\n",
      "node_features_sum.T:  tensor([1.7857, 3.3399, 0.0000])\n",
      "node_features_sum.T.size:  torch.Size([3])\n",
      "intermediate_node_features:  tensor([1.7857, 3.3399, 0.0000])\n",
      "intermediate_node_features.size:  torch.Size([3])\n",
      "edge_features index:  1\n",
      "edge_features:  tensor([1., 0., 1.])\n",
      "edge_features.size:  torch.Size([3])\n",
      "edge_features.T:  tensor([1., 0., 1.])\n",
      "edge_features.T.size():  torch.Size([3])\n",
      "intermediate_edge_feature:  tensor([1., 0., 1.])\n",
      "intermediate_edge_feature.size:  torch.Size([3])\n",
      "intermediate_edge_feature.size dim 0:  3\n",
      "intermediate_features:  tensor([0.0000, 1.0736, 0.0000])\n",
      "intermediate_features.size:  torch.Size([3])\n",
      "original_edge_features[i].T:  tensor([1., 0., 1.])\n",
      "calculated updated edge_features[i]:  tensor([1.0000, 1.0736, 1.0000])\n",
      "actually updated edge_features[i]:  tensor([1.0000, 1.0736, 1.0000])\n",
      "********** EDGE UPDATED SUCCESSFULLY ****************\n",
      "firstNodeIndex:  0\n",
      "secondNodeIndex:  1\n",
      "node_features[firstNodeIndex]:  tensor([0.0000, 2.5543, 0.0000])\n",
      "node_features[secondNodeIndex]:  tensor([0.0000, 2.3608, 1.0000])\n",
      "node_features_sum:  tensor([0.0000, 4.9151, 1.0000])\n",
      "node_features_sum.size:  torch.Size([3])\n",
      "node_features_sum.T:  tensor([0.0000, 4.9151, 1.0000])\n",
      "node_features_sum.T.size:  torch.Size([3])\n",
      "intermediate_node_features:  tensor([0.0000, 4.9151, 1.0000])\n",
      "intermediate_node_features.size:  torch.Size([3])\n",
      "edge_features index:  2\n",
      "edge_features:  tensor([0., 1., 0.])\n",
      "edge_features.size:  torch.Size([3])\n",
      "edge_features.T:  tensor([0., 1., 0.])\n",
      "edge_features.T.size():  torch.Size([3])\n",
      "intermediate_edge_feature:  tensor([0., 1., 0.])\n",
      "intermediate_edge_feature.size:  torch.Size([3])\n",
      "intermediate_edge_feature.size dim 0:  3\n",
      "intermediate_features:  tensor([0.0000, 1.5516, 0.0000])\n",
      "intermediate_features.size:  torch.Size([3])\n",
      "original_edge_features[i].T:  tensor([0., 1., 0.])\n",
      "calculated updated edge_features[i]:  tensor([0.0000, 2.5516, 0.0000])\n",
      "actually updated edge_features[i]:  tensor([0.0000, 2.5516, 0.0000])\n",
      "********** EDGE UPDATED SUCCESSFULLY ****************\n",
      "firstNodeIndex:  1\n",
      "secondNodeIndex:  0\n",
      "node_features[firstNodeIndex]:  tensor([0.0000, 2.3608, 1.0000])\n",
      "node_features[secondNodeIndex]:  tensor([0.0000, 2.5543, 0.0000])\n",
      "node_features_sum:  tensor([0.0000, 4.9151, 1.0000])\n",
      "node_features_sum.size:  torch.Size([3])\n",
      "node_features_sum.T:  tensor([0.0000, 4.9151, 1.0000])\n",
      "node_features_sum.T.size:  torch.Size([3])\n",
      "intermediate_node_features:  tensor([0.0000, 4.9151, 1.0000])\n",
      "intermediate_node_features.size:  torch.Size([3])\n",
      "edge_features index:  3\n",
      "edge_features:  tensor([0., 1., 0.])\n",
      "edge_features.size:  torch.Size([3])\n",
      "edge_features.T:  tensor([0., 1., 0.])\n",
      "edge_features.T.size():  torch.Size([3])\n",
      "intermediate_edge_feature:  tensor([0., 1., 0.])\n",
      "intermediate_edge_feature.size:  torch.Size([3])\n",
      "intermediate_edge_feature.size dim 0:  3\n",
      "intermediate_features:  tensor([0.0000, 1.5516, 0.0000])\n",
      "intermediate_features.size:  torch.Size([3])\n",
      "original_edge_features[i].T:  tensor([0., 1., 0.])\n",
      "calculated updated edge_features[i]:  tensor([0.0000, 2.5516, 0.0000])\n",
      "actually updated edge_features[i]:  tensor([0.0000, 2.5516, 0.0000])\n",
      "********** EDGE UPDATED SUCCESSFULLY ****************\n",
      "after layer propogation 1\n",
      "node_out_features:  tensor([[0.0000, 2.5543, 0.0000],\n",
      "        [0.0000, 2.3608, 1.0000],\n",
      "        [1.7857, 0.7857, 0.0000]])\n",
      "edge_out_features:  tensor([[1.4568, 1.0736, 1.0000],\n",
      "        [1.0000, 1.0736, 1.0000],\n",
      "        [0.0000, 2.5516, 0.0000],\n",
      "        [0.0000, 2.5516, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# one layer test of node and edge update equations\n",
    "node_features = torch.Tensor([[0, 1, 0],\n",
    "                          [0, 1, 1],\n",
    "                          [1, 0, 0]])\n",
    "edge_index = torch.Tensor([[2, 0, 0, 1],\n",
    "                       [0, 2, 1, 0]])\n",
    "edge_features = torch.Tensor([[1, 0, 1],\n",
    "                         [1, 0, 1],\n",
    "                         [0, 1, 0],\n",
    "                         [0, 1, 0]])\n",
    "\n",
    "print(\"node_features: \", node_features)\n",
    "print(\"edge_index: \", edge_index)\n",
    "print(\"edge_features: \", edge_features)\n",
    "\n",
    "# Node update layer\n",
    "node_update_layer = NodeFeatures(c_in1=3, c_out1=3, c_out2=3)\n",
    "\n",
    "# FCNN_one\n",
    "# Linear layer 1\n",
    "node_update_layer.FCNN_one.fc1.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "node_update_layer.FCNN_one.fc1.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "# Linear layer 2\n",
    "node_update_layer.FCNN_one.fc2.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "node_update_layer.FCNN_one.fc2.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "# FCNN_two\n",
    "# Linear layer 1\n",
    "node_update_layer.FCNN_two.fc1.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "node_update_layer.FCNN_two.fc1.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "# Linear layer 2\n",
    "node_update_layer.FCNN_two.fc2.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "node_update_layer.FCNN_two.fc2.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "# Edge update layer\n",
    "edge_update_layer = EdgeFeatures(c_in1=3, c_out1=3, c_out2=3)\n",
    "\n",
    "# FCNN_one\n",
    "# Linear layer 1\n",
    "edge_update_layer.FCNN_one.fc1.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "edge_update_layer.FCNN_one.fc1.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "# Lienar layer 2\n",
    "edge_update_layer.FCNN_one.fc2.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "edge_update_layer.FCNN_one.fc2.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "# FCNN_two\n",
    "# Linear layer 1\n",
    "edge_update_layer.FCNN_two.fc1.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "edge_update_layer.FCNN_two.fc1.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "# Linear layer 2\n",
    "edge_update_layer.FCNN_two.fc2.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "edge_update_layer.FCNN_two.fc2.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "with torch.no_grad():\n",
    "    node_out_features = node_update_layer(node_features, edge_index, edge_features)\n",
    "    edge_out_features = edge_update_layer(node_features, edge_index, edge_features)\n",
    "\n",
    "print(\"after layer propogation 1\")\n",
    "print(\"node_out_features: \", node_out_features)\n",
    "print(\"edge_out_features: \", edge_out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae1c3a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_features:  tensor([[0., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 0.]])\n",
      "edge_index:  tensor([[2., 0., 0., 1.],\n",
      "        [0., 2., 1., 0.]])\n",
      "edge_features:  tensor([[1., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n",
      "intermediate_node_feature:  tensor([0.5938, 1.5938, 0.4062])\n",
      "intermediate_node_feature.size:  torch.Size([3])\n",
      "actually updated node_features[i]:  tensor([0.0000, 2.5543, 0.0000])\n",
      "actually updated node_features[i].size():  torch.Size([3])\n",
      "********** NODE UPDATED SUCCESSFULLY ****************\n",
      "intermediate_node_feature:  tensor([0., 2., 1.])\n",
      "intermediate_node_feature.size:  torch.Size([3])\n",
      "actually updated node_features[i]:  tensor([0.0000, 2.3608, 1.0000])\n",
      "actually updated node_features[i].size():  torch.Size([3])\n",
      "********** NODE UPDATED SUCCESSFULLY ****************\n",
      "intermediate_node_feature:  tensor([1.0000, 1.0000, 0.0000])\n",
      "intermediate_node_feature.size:  torch.Size([3])\n",
      "actually updated node_features[i]:  tensor([1.7857, 0.7857, 0.0000])\n",
      "actually updated node_features[i].size():  torch.Size([3])\n",
      "********** NODE UPDATED SUCCESSFULLY ****************\n",
      "firstNodeIndex:  2\n",
      "secondNodeIndex:  0\n",
      "node_features[firstNodeIndex]:  tensor([1.7857, 0.7857, 0.0000])\n",
      "node_features[secondNodeIndex]:  tensor([0.0000, 2.5543, 0.0000])\n",
      "node_features_sum:  tensor([1.7857, 3.3399, 0.0000])\n",
      "node_features_sum.size:  torch.Size([3])\n",
      "node_features_sum.T:  tensor([1.7857, 3.3399, 0.0000])\n",
      "node_features_sum.T.size:  torch.Size([3])\n",
      "intermediate_node_features:  tensor([1.7857, 3.3399, 0.0000])\n",
      "intermediate_node_features.size:  torch.Size([3])\n",
      "edge_features index:  0\n",
      "edge_features:  tensor([1., 0., 1.])\n",
      "edge_features.size:  torch.Size([3])\n",
      "edge_features.T:  tensor([1., 0., 1.])\n",
      "edge_features.T.size():  torch.Size([3])\n",
      "intermediate_edge_feature:  tensor([1., 0., 1.])\n",
      "intermediate_edge_feature.size:  torch.Size([3])\n",
      "intermediate_edge_feature.size dim 0:  3\n",
      "intermediate_features:  tensor([0.4568, 1.0736, 0.0000])\n",
      "intermediate_features.size:  torch.Size([3])\n",
      "original_edge_features[i].T:  tensor([1., 0., 1.])\n",
      "calculated updated edge_features[i]:  tensor([1.4568, 1.0736, 1.0000])\n",
      "actually updated edge_features[i]:  tensor([1.4568, 1.0736, 1.0000])\n",
      "********** EDGE UPDATED SUCCESSFULLY ****************\n",
      "firstNodeIndex:  0\n",
      "secondNodeIndex:  2\n",
      "node_features[firstNodeIndex]:  tensor([0.0000, 2.5543, 0.0000])\n",
      "node_features[secondNodeIndex]:  tensor([1.7857, 0.7857, 0.0000])\n",
      "node_features_sum:  tensor([1.7857, 3.3399, 0.0000])\n",
      "node_features_sum.size:  torch.Size([3])\n",
      "node_features_sum.T:  tensor([1.7857, 3.3399, 0.0000])\n",
      "node_features_sum.T.size:  torch.Size([3])\n",
      "intermediate_node_features:  tensor([1.7857, 3.3399, 0.0000])\n",
      "intermediate_node_features.size:  torch.Size([3])\n",
      "edge_features index:  1\n",
      "edge_features:  tensor([1., 0., 1.])\n",
      "edge_features.size:  torch.Size([3])\n",
      "edge_features.T:  tensor([1., 0., 1.])\n",
      "edge_features.T.size():  torch.Size([3])\n",
      "intermediate_edge_feature:  tensor([1., 0., 1.])\n",
      "intermediate_edge_feature.size:  torch.Size([3])\n",
      "intermediate_edge_feature.size dim 0:  3\n",
      "intermediate_features:  tensor([0.0000, 1.0736, 0.0000])\n",
      "intermediate_features.size:  torch.Size([3])\n",
      "original_edge_features[i].T:  tensor([1., 0., 1.])\n",
      "calculated updated edge_features[i]:  tensor([1.0000, 1.0736, 1.0000])\n",
      "actually updated edge_features[i]:  tensor([1.0000, 1.0736, 1.0000])\n",
      "********** EDGE UPDATED SUCCESSFULLY ****************\n",
      "firstNodeIndex:  0\n",
      "secondNodeIndex:  1\n",
      "node_features[firstNodeIndex]:  tensor([0.0000, 2.5543, 0.0000])\n",
      "node_features[secondNodeIndex]:  tensor([0.0000, 2.3608, 1.0000])\n",
      "node_features_sum:  tensor([0.0000, 4.9151, 1.0000])\n",
      "node_features_sum.size:  torch.Size([3])\n",
      "node_features_sum.T:  tensor([0.0000, 4.9151, 1.0000])\n",
      "node_features_sum.T.size:  torch.Size([3])\n",
      "intermediate_node_features:  tensor([0.0000, 4.9151, 1.0000])\n",
      "intermediate_node_features.size:  torch.Size([3])\n",
      "edge_features index:  2\n",
      "edge_features:  tensor([0., 1., 0.])\n",
      "edge_features.size:  torch.Size([3])\n",
      "edge_features.T:  tensor([0., 1., 0.])\n",
      "edge_features.T.size():  torch.Size([3])\n",
      "intermediate_edge_feature:  tensor([0., 1., 0.])\n",
      "intermediate_edge_feature.size:  torch.Size([3])\n",
      "intermediate_edge_feature.size dim 0:  3\n",
      "intermediate_features:  tensor([0.0000, 1.5516, 0.0000])\n",
      "intermediate_features.size:  torch.Size([3])\n",
      "original_edge_features[i].T:  tensor([0., 1., 0.])\n",
      "calculated updated edge_features[i]:  tensor([0.0000, 2.5516, 0.0000])\n",
      "actually updated edge_features[i]:  tensor([0.0000, 2.5516, 0.0000])\n",
      "********** EDGE UPDATED SUCCESSFULLY ****************\n",
      "firstNodeIndex:  1\n",
      "secondNodeIndex:  0\n",
      "node_features[firstNodeIndex]:  tensor([0.0000, 2.3608, 1.0000])\n",
      "node_features[secondNodeIndex]:  tensor([0.0000, 2.5543, 0.0000])\n",
      "node_features_sum:  tensor([0.0000, 4.9151, 1.0000])\n",
      "node_features_sum.size:  torch.Size([3])\n",
      "node_features_sum.T:  tensor([0.0000, 4.9151, 1.0000])\n",
      "node_features_sum.T.size:  torch.Size([3])\n",
      "intermediate_node_features:  tensor([0.0000, 4.9151, 1.0000])\n",
      "intermediate_node_features.size:  torch.Size([3])\n",
      "edge_features index:  3\n",
      "edge_features:  tensor([0., 1., 0.])\n",
      "edge_features.size:  torch.Size([3])\n",
      "edge_features.T:  tensor([0., 1., 0.])\n",
      "edge_features.T.size():  torch.Size([3])\n",
      "intermediate_edge_feature:  tensor([0., 1., 0.])\n",
      "intermediate_edge_feature.size:  torch.Size([3])\n",
      "intermediate_edge_feature.size dim 0:  3\n",
      "intermediate_features:  tensor([0.0000, 1.5516, 0.0000])\n",
      "intermediate_features.size:  torch.Size([3])\n",
      "original_edge_features[i].T:  tensor([0., 1., 0.])\n",
      "calculated updated edge_features[i]:  tensor([0.0000, 2.5516, 0.0000])\n",
      "actually updated edge_features[i]:  tensor([0.0000, 2.5516, 0.0000])\n",
      "********** EDGE UPDATED SUCCESSFULLY ****************\n",
      "after layer propogation  1\n",
      "node_out_features:  tensor([[0.0000, 2.5543, 0.0000],\n",
      "        [0.0000, 2.3608, 1.0000],\n",
      "        [1.7857, 0.7857, 0.0000]])\n",
      "edge_out_features:  tensor([[1.4568, 1.0736, 1.0000],\n",
      "        [1.0000, 1.0736, 1.0000],\n",
      "        [0.0000, 2.5516, 0.0000],\n",
      "        [0.0000, 2.5516, 0.0000]])\n",
      "intermediate_node_feature:  tensor([1.0832, 4.2134, 0.4062])\n",
      "intermediate_node_feature.size:  torch.Size([3])\n",
      "actually updated node_features[i]:  tensor([0.0000, 4.1036, 0.0000])\n",
      "actually updated node_features[i].size():  torch.Size([3])\n",
      "********** NODE UPDATED SUCCESSFULLY ****************\n",
      "intermediate_node_feature:  tensor([0.0000, 4.9151, 1.0000])\n",
      "intermediate_node_feature.size:  torch.Size([3])\n",
      "actually updated node_features[i]:  tensor([0.0000, 3.9028, 1.0000])\n",
      "actually updated node_features[i].size():  torch.Size([3])\n",
      "********** NODE UPDATED SUCCESSFULLY ****************\n",
      "intermediate_node_feature:  tensor([1.7857, 3.3399, 0.0000])\n",
      "intermediate_node_feature.size:  torch.Size([3])\n",
      "actually updated node_features[i]:  tensor([1.8485, 2.1140, 0.0000])\n",
      "actually updated node_features[i].size():  torch.Size([3])\n",
      "********** NODE UPDATED SUCCESSFULLY ****************\n",
      "firstNodeIndex:  2\n",
      "secondNodeIndex:  0\n",
      "node_features[firstNodeIndex]:  tensor([1.8485, 2.1140, 0.0000])\n",
      "node_features[secondNodeIndex]:  tensor([0.0000, 4.1036, 0.0000])\n",
      "node_features_sum:  tensor([1.8485, 6.2176, 0.0000])\n",
      "node_features_sum.size:  torch.Size([3])\n",
      "node_features_sum.T:  tensor([1.8485, 6.2176, 0.0000])\n",
      "node_features_sum.T.size:  torch.Size([3])\n",
      "intermediate_node_features:  tensor([1.8485, 6.2176, 0.0000])\n",
      "intermediate_node_features.size:  torch.Size([3])\n",
      "edge_features index:  0\n",
      "edge_features:  tensor([1.4568, 1.0736, 1.0000])\n",
      "edge_features.size:  torch.Size([3])\n",
      "edge_features.T:  tensor([1.4568, 1.0736, 1.0000])\n",
      "edge_features.T.size():  torch.Size([3])\n",
      "intermediate_edge_feature:  tensor([1.4568, 1.0736, 1.0000])\n",
      "intermediate_edge_feature.size:  torch.Size([3])\n",
      "intermediate_edge_feature.size dim 0:  3\n",
      "intermediate_features:  tensor([0.0000, 1.4647, 0.0000])\n",
      "intermediate_features.size:  torch.Size([3])\n",
      "original_edge_features[i].T:  tensor([1.4568, 1.0736, 1.0000])\n",
      "calculated updated edge_features[i]:  tensor([1.4568, 2.5383, 1.0000])\n",
      "actually updated edge_features[i]:  tensor([1.4568, 2.5383, 1.0000])\n",
      "********** EDGE UPDATED SUCCESSFULLY ****************\n",
      "firstNodeIndex:  0\n",
      "secondNodeIndex:  2\n",
      "node_features[firstNodeIndex]:  tensor([0.0000, 4.1036, 0.0000])\n",
      "node_features[secondNodeIndex]:  tensor([1.8485, 2.1140, 0.0000])\n",
      "node_features_sum:  tensor([1.8485, 6.2176, 0.0000])\n",
      "node_features_sum.size:  torch.Size([3])\n",
      "node_features_sum.T:  tensor([1.8485, 6.2176, 0.0000])\n",
      "node_features_sum.T.size:  torch.Size([3])\n",
      "intermediate_node_features:  tensor([1.8485, 6.2176, 0.0000])\n",
      "intermediate_node_features.size:  torch.Size([3])\n",
      "edge_features index:  1\n",
      "edge_features:  tensor([1.0000, 1.0736, 1.0000])\n",
      "edge_features.size:  torch.Size([3])\n",
      "edge_features.T:  tensor([1.0000, 1.0736, 1.0000])\n",
      "edge_features.T.size():  torch.Size([3])\n",
      "intermediate_edge_feature:  tensor([1.0000, 1.0736, 1.0000])\n",
      "intermediate_edge_feature.size:  torch.Size([3])\n",
      "intermediate_edge_feature.size dim 0:  3\n",
      "intermediate_features:  tensor([-0.0000, 1.5058, 0.0000])\n",
      "intermediate_features.size:  torch.Size([3])\n",
      "original_edge_features[i].T:  tensor([1.0000, 1.0736, 1.0000])\n",
      "calculated updated edge_features[i]:  tensor([1.0000, 2.5794, 1.0000])\n",
      "actually updated edge_features[i]:  tensor([1.0000, 2.5794, 1.0000])\n",
      "********** EDGE UPDATED SUCCESSFULLY ****************\n",
      "firstNodeIndex:  0\n",
      "secondNodeIndex:  1\n",
      "node_features[firstNodeIndex]:  tensor([0.0000, 4.1036, 0.0000])\n",
      "node_features[secondNodeIndex]:  tensor([0.0000, 3.9028, 1.0000])\n",
      "node_features_sum:  tensor([0.0000, 8.0064, 1.0000])\n",
      "node_features_sum.size:  torch.Size([3])\n",
      "node_features_sum.T:  tensor([0.0000, 8.0064, 1.0000])\n",
      "node_features_sum.T.size:  torch.Size([3])\n",
      "intermediate_node_features:  tensor([0.0000, 8.0064, 1.0000])\n",
      "intermediate_node_features.size:  torch.Size([3])\n",
      "edge_features index:  2\n",
      "edge_features:  tensor([0.0000, 2.5516, 0.0000])\n",
      "edge_features.size:  torch.Size([3])\n",
      "edge_features.T:  tensor([0.0000, 2.5516, 0.0000])\n",
      "edge_features.T.size():  torch.Size([3])\n",
      "intermediate_edge_feature:  tensor([0.0000, 2.5516, 0.0000])\n",
      "intermediate_edge_feature.size:  torch.Size([3])\n",
      "intermediate_edge_feature.size dim 0:  3\n",
      "intermediate_features:  tensor([0., 0., 0.])\n",
      "intermediate_features.size:  torch.Size([3])\n",
      "original_edge_features[i].T:  tensor([0.0000, 2.5516, 0.0000])\n",
      "calculated updated edge_features[i]:  tensor([0.0000, 2.5516, 0.0000])\n",
      "actually updated edge_features[i]:  tensor([0.0000, 2.5516, 0.0000])\n",
      "********** EDGE UPDATED SUCCESSFULLY ****************\n",
      "firstNodeIndex:  1\n",
      "secondNodeIndex:  0\n",
      "node_features[firstNodeIndex]:  tensor([0.0000, 3.9028, 1.0000])\n",
      "node_features[secondNodeIndex]:  tensor([0.0000, 4.1036, 0.0000])\n",
      "node_features_sum:  tensor([0.0000, 8.0064, 1.0000])\n",
      "node_features_sum.size:  torch.Size([3])\n",
      "node_features_sum.T:  tensor([0.0000, 8.0064, 1.0000])\n",
      "node_features_sum.T.size:  torch.Size([3])\n",
      "intermediate_node_features:  tensor([0.0000, 8.0064, 1.0000])\n",
      "intermediate_node_features.size:  torch.Size([3])\n",
      "edge_features index:  3\n",
      "edge_features:  tensor([0.0000, 2.5516, 0.0000])\n",
      "edge_features.size:  torch.Size([3])\n",
      "edge_features.T:  tensor([0.0000, 2.5516, 0.0000])\n",
      "edge_features.T.size():  torch.Size([3])\n",
      "intermediate_edge_feature:  tensor([0.0000, 2.5516, 0.0000])\n",
      "intermediate_edge_feature.size:  torch.Size([3])\n",
      "intermediate_edge_feature.size dim 0:  3\n",
      "intermediate_features:  tensor([0.0000, 1.5656, 0.0000])\n",
      "intermediate_features.size:  torch.Size([3])\n",
      "original_edge_features[i].T:  tensor([0.0000, 2.5516, 0.0000])\n",
      "calculated updated edge_features[i]:  tensor([0.0000, 4.1172, 0.0000])\n",
      "actually updated edge_features[i]:  tensor([0.0000, 4.1172, 0.0000])\n",
      "********** EDGE UPDATED SUCCESSFULLY ****************\n",
      "after layer propogation  2\n",
      "node_out_features:  tensor([[0.0000, 4.1036, 0.0000],\n",
      "        [0.0000, 3.9028, 1.0000],\n",
      "        [1.8485, 2.1140, 0.0000]])\n",
      "edge_out_features:  tensor([[1.4568, 2.5383, 1.0000],\n",
      "        [1.0000, 2.5794, 1.0000],\n",
      "        [0.0000, 2.5516, 0.0000],\n",
      "        [0.0000, 4.1172, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# two layer test of node and edge update equations\n",
    "node_features = torch.Tensor([[0, 1, 0],\n",
    "                          [0, 1, 1],\n",
    "                          [1, 0, 0]])\n",
    "edge_index = torch.Tensor([[2, 0, 0, 1],\n",
    "                       [0, 2, 1, 0]])\n",
    "edge_features = torch.Tensor([[1, 0, 1],\n",
    "                         [1, 0, 1],\n",
    "                         [0, 1, 0],\n",
    "                         [0, 1, 0]])\n",
    "\n",
    "print(\"node_features: \", node_features)\n",
    "print(\"edge_index: \", edge_index)\n",
    "print(\"edge_features: \", edge_features)\n",
    "\n",
    "# Node update layer\n",
    "node_update_layer = NodeFeatures(c_in1=3, c_out1=3, c_out2=3)\n",
    "\n",
    "# FCNN_one\n",
    "# Linear layer 1\n",
    "node_update_layer.FCNN_one.fc1.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "node_update_layer.FCNN_one.fc1.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "# Linear layer 2\n",
    "node_update_layer.FCNN_one.fc2.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "node_update_layer.FCNN_one.fc2.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "# FCNN_two\n",
    "# Linear layer 1\n",
    "node_update_layer.FCNN_two.fc1.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "node_update_layer.FCNN_two.fc1.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "# Linear layer 2\n",
    "node_update_layer.FCNN_two.fc2.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "node_update_layer.FCNN_two.fc2.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "# Edge update layer\n",
    "edge_update_layer = EdgeFeatures(c_in1=3, c_out1=3, c_out2=3)\n",
    "\n",
    "# FCNN_one\n",
    "# Linear layer 1\n",
    "edge_update_layer.FCNN_one.fc1.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "edge_update_layer.FCNN_one.fc1.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "# Lienar layer 2\n",
    "edge_update_layer.FCNN_one.fc2.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "edge_update_layer.FCNN_one.fc2.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "# FCNN_two\n",
    "# Linear layer 1\n",
    "edge_update_layer.FCNN_two.fc1.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "edge_update_layer.FCNN_two.fc1.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "# Linear layer 2\n",
    "edge_update_layer.FCNN_two.fc2.weight.data = torch.Tensor([[1., 0., 0.], \n",
    "                                             [0., 1., 0.],\n",
    "                                             [0., 0., 1.]])\n",
    "edge_update_layer.FCNN_two.fc2.bias.data = torch.Tensor([0., 0., 0.])\n",
    "\n",
    "for i in range(2):\n",
    "    with torch.no_grad():\n",
    "        node_out_features = node_update_layer(node_features, edge_index, edge_features)\n",
    "        edge_out_features = edge_update_layer(node_features, edge_index, edge_features)\n",
    "        \n",
    "    print(\"after layer propogation \", i + 1)\n",
    "    print(\"node_out_features: \", node_out_features)\n",
    "    print(\"edge_out_features: \", edge_out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "040da71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node update layers: \n",
      "Parameter containing:\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "\n",
      "edge update layers: \n",
      "Parameter containing:\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"node update layers: \")\n",
    "print(node_update_layer.FCNN_one.fc1.weight)\n",
    "print(node_update_layer.FCNN_one.fc1.bias)\n",
    "print(node_update_layer.FCNN_two.fc2.weight)\n",
    "print(node_update_layer.FCNN_two.fc2.bias)\n",
    "\n",
    "print(\"\\nedge update layers: \")\n",
    "print(edge_update_layer.FCNN_one.fc1.weight)\n",
    "print(edge_update_layer.FCNN_one.fc1.bias)\n",
    "print(edge_update_layer.FCNN_two.fc2.weight)\n",
    "print(edge_update_layer.FCNN_two.fc2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e58dcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_features:  tensor([[0., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 0.]])\n",
      "edge_index:  tensor([[2., 0., 0., 1.],\n",
      "        [0., 2., 1., 0.]])\n",
      "edge_features:  tensor([[1., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n",
      "after layer propogation  1\n",
      "node_out_features:  tensor([[0.0000, 4.1036, 0.0000],\n",
      "        [0.0000, 3.9028, 1.0000],\n",
      "        [1.8485, 2.1140, 0.0000]])\n",
      "edge_out_features:  tensor([[1.4568, 2.5383, 1.0000],\n",
      "        [1.0000, 2.5794, 1.0000],\n",
      "        [0.0000, 2.5516, 0.0000],\n",
      "        [0.0000, 4.1172, 0.0000]])\n",
      "after layer propogation  2\n",
      "node_out_features:  tensor([[0.0000, 4.1036, 0.0000],\n",
      "        [0.0000, 3.9028, 1.0000],\n",
      "        [1.8485, 2.1140, 0.0000]])\n",
      "edge_out_features:  tensor([[1.4568, 2.5383, 1.0000],\n",
      "        [1.0000, 2.5794, 1.0000],\n",
      "        [0.0000, 2.5516, 0.0000],\n",
      "        [0.0000, 4.1172, 0.0000]])\n",
      "after layer propogation  3\n",
      "node_out_features:  tensor([[0.0000, 4.1036, 0.0000],\n",
      "        [0.0000, 3.9028, 1.0000],\n",
      "        [1.8485, 2.1140, 0.0000]])\n",
      "edge_out_features:  tensor([[1.4568, 2.5383, 1.0000],\n",
      "        [1.0000, 2.5794, 1.0000],\n",
      "        [0.0000, 2.5516, 0.0000],\n",
      "        [0.0000, 4.1172, 0.0000]])\n",
      "after layer propogation  4\n",
      "node_out_features:  tensor([[0.0000, 4.1036, 0.0000],\n",
      "        [0.0000, 3.9028, 1.0000],\n",
      "        [1.8485, 2.1140, 0.0000]])\n",
      "edge_out_features:  tensor([[1.4568, 2.5383, 1.0000],\n",
      "        [1.0000, 2.5794, 1.0000],\n",
      "        [0.0000, 2.5516, 0.0000],\n",
      "        [0.0000, 4.1172, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "node_features = torch.Tensor([[0, 1, 0],\n",
    "                          [0, 1, 1],\n",
    "                          [1, 0, 0]])\n",
    "edge_index = torch.Tensor([[2, 0, 0, 1],\n",
    "                       [0, 2, 1, 0]])\n",
    "edge_features = torch.Tensor([[1, 0, 1],\n",
    "                         [1, 0, 1],\n",
    "                         [0, 1, 0],\n",
    "                         [0, 1, 0]])\n",
    "\n",
    "print(\"node_features: \", node_features)\n",
    "print(\"edge_index: \", edge_index)\n",
    "print(\"edge_features: \", edge_features)\n",
    "\n",
    "graph2graph_layer = Graph2Graph(c_in1=3, c_out1=3, c_out2=3)\n",
    "\n",
    "for i in range(4):\n",
    "    with torch.no_grad():\n",
    "        node_features, edge_features = graph2graph_layer(node_features, edge_index, edge_features)\n",
    "        \n",
    "    print(\"after layer propogation \", i + 1)\n",
    "    print(\"node_out_features: \", node_out_features)\n",
    "    print(\"edge_out_features: \", edge_out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e57b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, dataloader2, model, loss_fn, optimizer):\n",
    "    # print(\"before size\")\n",
    "    size = len(dataloader.dataset)\n",
    "    # print(\"after size\")\n",
    "    # print(size)\n",
    "    loss_batch = []\n",
    "    for batch, (X, y) in enumerate(dataloader.dataset):\n",
    "    # for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        # print(len(X))\n",
    "        # print(X[0].shape)\n",
    "        # print(X[1].shape)\n",
    "        ninput = X[0].float()\n",
    "        # print(ninput.shape)\n",
    "        ainput = X[1].float()\n",
    "        # print(ainput.shape)\n",
    "        # print(ainput.sum(dim=-1, keepdims=True))\n",
    "        einput = X[2].float()\n",
    "        pred = model(X)\n",
    "        # print(pred.shape)\n",
    "        yReshaped = torch.Tensor([y]).reshape(1, 1, 1)\n",
    "        # print(yReshaped.shape)\n",
    "        # print(\"Prediction: %s, Actual value %s\", pred, yReshaped)\n",
    "        loss = loss_fn(pred, yReshaped)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_batch.append(loss.item())\n",
    "\n",
    "    loss_epoch = np.average(loss_batch)\n",
    "\n",
    "    print(\"Training loss: \", loss_epoch)\n",
    "\n",
    "    val_loss_batch = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloader2.dataset):\n",
    "        # for batch, (X, y) in enumerate(dataloader2):\n",
    "            ninput = X[0].float()\n",
    "            ainput = X[1].float()\n",
    "            einput = X[2].float()\n",
    "            pred = model(ninput, ainput, einput)\n",
    "            yReshaped = torch.Tensor([y]).reshape(1, 1, 1)\n",
    "            loss = loss_fn(pred, yReshaped)\n",
    "      \n",
    "            val_loss_batch.append(loss.item())\n",
    "    \n",
    "    val_loss_epoch = np.average(val_loss_batch)\n",
    "\n",
    "    print(\"Validation loss: \", val_loss_epoch)\n",
    "\n",
    "    return loss_epoch, val_loss_epoch\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader.dataset:\n",
    "        # for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    # print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "621e2f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/adityabehal/opt/anaconda3/envs/custom-gnn/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/adityabehal/opt/anaconda3/envs/custom-gnn/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'CustomDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# we need to check to see if train_data and val_data is being shuffled before each epoch along with playing around with different initializations (and can do multiple reruns)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# we can also try SGD for a few epochs (5) before doing Adam or maybe try SGD for all 20 epochs\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# we can run several jupyter notebooks in parallel\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m train_loss_epoch_value, val_loss_epoch_value \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(train_loss_epoch_value)\n\u001b[1;32m     17\u001b[0m val_loss\u001b[38;5;241m.\u001b[39mappend(val_loss_epoch_value)\n",
      "Cell \u001b[0;32mIn[28], line 7\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, dataloader2, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print(\"after size\")\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# print(size)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m loss_batch \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# for batch, (X, y) in enumerate(dataloader):\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Compute prediction and loss\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# print(len(X))\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# print(X[0].shape)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# print(X[1].shape)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     ninput \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# print(ninput.shape)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/custom-gnn/lib/python3.8/site-packages/torch/utils/data/dataloader.py:435\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/custom-gnn/lib/python3.8/site-packages/torch/utils/data/dataloader.py:381\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/custom-gnn/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1034\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1027\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1034\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/custom-gnn/lib/python3.8/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/custom-gnn/lib/python3.8/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/custom-gnn/lib/python3.8/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/custom-gnn/lib/python3.8/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/custom-gnn/lib/python3.8/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/custom-gnn/lib/python3.8/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "loss_epochs = []\n",
    "val_loss_epochs = []\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    # we need to check to see if train_data and val_data is being shuffled before each epoch along with playing around with different initializations (and can do multiple reruns)\n",
    "    # we can also try SGD for a few epochs (5) before doing Adam or maybe try SGD for all 20 epochs\n",
    "    # we can run several jupyter notebooks in parallel\n",
    "    train_loss_epoch_value, val_loss_epoch_value = train_loop(train_data_loader.dataset, val_data_loader.dataset, model, loss_fn, optimizer)\n",
    "    train_loss.append(train_loss_epoch_value)\n",
    "    val_loss.append(val_loss_epoch_value)\n",
    "    # test_loop(test_data, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ef3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = train_data_loader.dataset\n",
    "\n",
    "for batch, (X, y) in enumerate(dataloader.dataset):\n",
    "    print(batch)\n",
    "    '''\n",
    "    print(len(X))\n",
    "    print(X[0].shape)\n",
    "    print(X[1].shape)\n",
    "    print(X[2].shape)\n",
    "    ninput = X[0].float()\n",
    "    ainput = X[1].float()\n",
    "    einput = X[2].float()\n",
    "    yReshaped = torch.Tensor([y]).reshape(1, 1, 1)\n",
    "    '''\n",
    "    print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf13968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11016639",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff4352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(dataloader.dataset.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(dataloader.dataset.dataset.graphInstances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af80e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(dataloader.dataset.dataset.solInstances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e516f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataloader.dataset.dataset.graphInstances.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ee4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataloader.dataset.dataset.solInstances.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb015923",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataloader.dataset.dataset.graphInstances.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff946077",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataloader.dataset.dataset.solInstances.__getitem__(9981))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b2f137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
